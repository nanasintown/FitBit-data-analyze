{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd #import pandas to manipulate the dataset\n",
    "from matplotlib import pyplot as plt #import the module matplotlib.pyplot to do visulization\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures    # function to generate polynomial and interaction features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error  # evaluation metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns  #data visualization library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data stored in the file 'kidney_disease.csv'\n",
    "df = pd.read_csv('kidney_disease.csv')\n",
    "\n",
    "# Drop columns that are not used\n",
    "df.drop(columns=['id','sg', 'su','pc','dm','pcc', 'cad','ba', 'bgr', 'sod', 'rbc','pot', 'wc', 'pe', 'ane','sc', 'al', 'hemo', 'htn', 'rc', 'pcv'],inplace=True)  # drop unrelevant columns\n",
    "\n",
    "# Print the first 5 rows of the DataFrame 'df'\n",
    "# the classification column is the label, CKD = Chronic Kidney Disease\n",
    "df.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing Datapoints: People in 45-55 age range\n",
    "df = df[df[\"age\"] >= 45]\n",
    "df = df[df[\"age\"] <= 55]\n",
    "df = df.reset_index(drop=True) # re-indexing\n",
    "\n",
    "# Change label to numeric value: 1 represents a person have CKD, otherwise 0.\n",
    "df = df.replace('ckd', 1)\n",
    "df = df.replace('notckd', 0)\n",
    "df = df.dropna()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature and label\n",
    "# X represents feature, here is 'bu', which means blood urine\n",
    "X = df['bu'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# y represents label, here is 1 or 0, stands for \"have CKD\" or 'not CKD'\n",
    "y = df['classification'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, predict the whole data set without spliting into training and validation sets.\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "\n",
    "y_pred = clf.predict(X)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print('Training error: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix to how well the model perform\n",
    "conf_mat = confusion_matrix(y, y_pred)\n",
    "# Visualize the confusion matrix \n",
    "ax= plt.subplot()\n",
    "sns.heatmap(conf_mat, annot=True, fmt='g', ax=ax)\n",
    "\n",
    "ax.set_xlabel('Predicted labels',fontsize=15)\n",
    "ax.set_ylabel('True labels',fontsize=15)\n",
    "ax.set_title('Confusion Matrix',fontsize=15)\n",
    "ax.xaxis.set_ticklabels(['below zero', 'above zero'],fontsize=15)\n",
    "ax.yaxis.set_ticklabels(['below zero', 'above zero'],fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the precision of the model\n",
    "precision = conf_mat[1,1]/(conf_mat[1,1]+conf_mat[0,1])\n",
    "print('Precision of the model: ', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting data into training and validation sets. Use test_size=0.2 so that the test set is 205 of the whole dataset\n",
    "X_perf, X_test, y_perf, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Check the length and see if each set have both class for fairness.\n",
    "print(len(X_perf), y_perf) # 69 datapoints\n",
    "print(len(X_test), y_test) # 18 datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold to split the dataset, k=3 so there will be 3 different sets\n",
    "k, shuffle, seed = 3, True, 42\n",
    "kf = KFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_val_acc, log_val_err = [], [] # validation set: accuracy score list and error list of Logistic Regression model\n",
    "log_train_acc, log_train_err = [], [] # training set: accuracy score list and error list of Logistic Regression model\n",
    "tree_train_acc, tree_train_err =[], [] # training set: accuracy score list and error list of Decision tree model\n",
    "tree_val_acc, tree_val_err =[], [] # validation set: accuracy score list and error list of Decision tree model\n",
    "# K-Fold to split the set. There will be 3 diffent sets\n",
    "for train_index, val_index in kf.split(X_perf):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    #Logistic Regression\n",
    "    # fit training set\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # predict both sets\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    \n",
    "    # calculate accuracy score and error\n",
    "    acc_val = accuracy_score(y_val, y_pred_val)\n",
    "    err_log_val = 1 - acc_val\n",
    "    log_val_acc.append(acc_val) # append accuracy score\n",
    "    log_val_err.append(err_log_val)\n",
    "    \n",
    "    acc_train = accuracy_score(y_train, y_pred_train)\n",
    "    err_log_train = 1 - acc_train\n",
    "    log_train_acc.append(acc_train)\n",
    "    log_train_err.append(err_log_train)\n",
    "    \n",
    "    # Decision Tree\n",
    "    model_tree = DecisionTreeClassifier(max_depth=2, criterion='entropy')\n",
    "    # fit training set\n",
    "    model_tree.fit(X_train, y_train)\n",
    "\n",
    "    # validation set\n",
    "    y_tree_val_pred = model_tree.predict(X_val)\n",
    "    acc_tree_val = accuracy_score(y_val, y_tree_val_pred)\n",
    "    err_tree_val = 1 - acc_tree_val\n",
    "    tree_val_acc.append(acc_tree_val)\n",
    "    tree_val_err.append(err_tree_val)\n",
    "    \n",
    "    # training set\n",
    "    y_train_pred = model_tree.predict(X_train)\n",
    "    acc_tree_train = accuracy_score(y_train, y_train_pred)\n",
    "    err_tree_train = 1 - acc_tree_train\n",
    "    \n",
    "    tree_train_acc.append(acc_tree_train)\n",
    "    tree_train_err.append(err_tree_train)\n",
    "    \n",
    "    \n",
    "\n",
    "# Print result\n",
    "print(\"[Logistic Regression] validation set accuracy score: \", log_val_acc)\n",
    "print(\"[Logistic Regression] validation set error score: \", log_val_err)\n",
    "print(\"[Logistic Regression] training set accuracy score: \" , log_train_acc)\n",
    "print(\"[Logistic Regression] training set error score: \", log_train_err)\n",
    "\n",
    "print(\"-\"*8)\n",
    "\n",
    "print(\"[Decision Tree] validation set accuracy score: \", tree_val_acc)\n",
    "print(\"[Decision Tree] validation set error score: \", tree_val_err)\n",
    "print(\"[Decision Tree] training set accuracy score: \" , tree_train_acc)\n",
    "print(\"[Decision Tree] training set error score: \", tree_train_err)\n",
    "\n",
    "print(\"-\"*8)\n",
    "\n",
    "avg_log_acc = np.average(log_val_acc)\n",
    "avg_tree_acc = np.average(tree_val_acc)\n",
    "print(\"[Logistic Regression] average validation accuracy: \", avg_log_acc)\n",
    "print(\"[Decision Tree] average validation accuracy: \", avg_tree_acc)\n",
    "print(\"-\"*8)\n",
    "\n",
    "avg_log_acc2 = np.average(log_train_acc)\n",
    "avg_tree_acc2 = np.average(tree_train_acc)\n",
    "print(\"[Logistic Regression] average training accuracy: \", avg_log_acc2)\n",
    "print(\"[Decision Tree] average training accuracy: \", avg_tree_acc2)\n",
    "print(\"-\"*8)\n",
    "\n",
    "avg_log_err = np.average(log_val_err)\n",
    "avg_tree_err = np.average(tree_val_err)\n",
    "print(\"[Logistic Regression] average validation error: \", avg_log_err)\n",
    "print(\"[Decision Tree] average validation error: \", avg_tree_err)\n",
    "print(\"-\"*8)\n",
    "\n",
    "avg_log_err2 = np.average(log_train_err)\n",
    "avg_tree_err2 = np.average(tree_train_err)\n",
    "print(\"[Logistic Regression] average training error: \", avg_log_err2)\n",
    "print(\"[Decision Tree] average training error: \", avg_tree_err2)\n",
    "print(\"-\"*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Blood Urine\")\n",
    "ax.set_yticks([0,1])\n",
    "ax.set_ylabel('CKD classification')\n",
    "ax.set_title(\"Blood Urine and CKD\")\n",
    "ax.scatter(X[:,0],y,s=50,c=\"skyblue\",label=\"training datapoints\")\n",
    "X_fit = np.linspace(-25, 25, 100) \n",
    "ax.scatter(X_fit, model_tree.predict(X_fit.reshape(-1, 1)),color='r',s=5,label='predicted label ($\\hat{y}=1$ if $h(x) > 0$)') \n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Decision Tree with the test set\n",
    "y_test_pred = model_tree.predict(X_test)\n",
    "\n",
    "# 0: As the size of the test set is quite small\n",
    "\n",
    "#Test Accuracy\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test accuracy: \", test_acc)\n",
    "\n",
    "# Test error\n",
    "test_err = 1 - test_acc\n",
    "\n",
    "print(\"Test error: \", test_err)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
